{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_poem(file_name):\n",
    "    with open(file_name, 'r', encoding=\"utf-8\") as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "ferdowsi_lines = read_poem('train_set/ferdowsi_train.txt')\n",
    "hafez_lines = read_poem('train_set/hafez_train.txt')\n",
    "molana_lines = read_poem('train_set/molavi_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferdowsi length: 9000\n",
      "Hafez length: 7700\n",
      "Molana length: 8000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ferdowsi length: {len(ferdowsi_lines)}\")\n",
    "print(f\"Hafez length: {len(hafez_lines)}\")\n",
    "print(f\"Molana length: {len(molana_lines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = ferdowsi_lines + hafez_lines + molana_lines\n",
    "p_ferdowsdi = len(ferdowsi_lines) / len(all_lines)\n",
    "p_hafez = len(hafez_lines) / len(all_lines)\n",
    "p_molana = len(molana_lines) / len(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferdowsi probability: 0.3643724696356275\n",
      "Hafez probability: 0.3117408906882591\n",
      "Molana probability: 0.32388663967611336\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ferdowsi probability: {p_ferdowsdi}\")\n",
    "print(f\"Hafez probability: {p_hafez}\")\n",
    "print(f\"Molana probability: {p_molana}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines_with_token = [f\"<S> {l} </S>\" for l in all_lines]\n",
    "ferdowsi_lines_with_token = [f\"<S> {l} </S>\" for l in ferdowsi_lines]\n",
    "hafez_lines_with_token = [f\"<S> {l} </S>\" for l in hafez_lines]\n",
    "molana_lines_with_token = [f\"<S> {l} </S>\" for l in molana_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S> جهان چون بزاری برآید همی </S>', '<S> بدو نیک روزی سرآید همی </S>', '<S> چو بستی کمر بر در راه آز </S>']\n",
      "['<S> جهان چون بزاری برآید همی </S>', '<S> بدو نیک روزی سرآید همی </S>', '<S> چو بستی کمر بر در راه آز </S>']\n",
      "['<S> الا یا ایها الساقی ادر کاسا و ناولها </S>', '<S> که عشق آسان نمود اول ولی افتاد مشکل\\u200cها </S>', '<S> به بوی نافه\\u200cای کاخر صبا زان طره بگشاید </S>']\n",
      "['<S> بشنو از نی ، چون حکایت می\\u200cکند </S>', '<S> واز جدائی\\u200cها شکایت می\\u200cکند </S>', '<S> کز نیستان تا مرا ببریده اند </S>']\n"
     ]
    }
   ],
   "source": [
    "print(all_lines_with_token[:3])\n",
    "print(ferdowsi_lines_with_token[:3])\n",
    "print(hafez_lines_with_token[:3])\n",
    "print(molana_lines_with_token[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = \" \".join(all_lines_with_token).split(\" \")\n",
    "ferdowsi_words = \" \".join(ferdowsi_lines_with_token).split(\" \")\n",
    "hafez_words = \" \".join(hafez_lines_with_token).split(\" \")\n",
    "molana_words = \" \".join(molana_lines_with_token).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S>', 'جهان', 'چون', 'بزاری', 'برآید', 'همی', '</S>', '<S>', 'بدو', 'نیک']\n",
      "['<S>', 'جهان', 'چون', 'بزاری', 'برآید', 'همی', '</S>', '<S>', 'بدو', 'نیک']\n",
      "['<S>', 'الا', 'یا', 'ایها', 'الساقی', 'ادر', 'کاسا', 'و', 'ناولها', '</S>']\n",
      "['<S>', 'بشنو', 'از', 'نی', '،', 'چون', 'حکایت', 'می\\u200cکند', '</S>', '<S>']\n"
     ]
    }
   ],
   "source": [
    "print(all_words[:10])\n",
    "print(ferdowsi_words[:10])\n",
    "print(hafez_words[:10])\n",
    "print(molana_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17158\n"
     ]
    }
   ],
   "source": [
    "all_words_set = set(all_words)\n",
    "print(len(all_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8075"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = [w for w in all_words_set if all_words.count(w) >= 2]\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: ferdowsi, 1: hafez, 2: molana\n",
    "unigram_p = [{}, {}, {}]\n",
    "for w in dictionary:\n",
    "    unigram_p[0][w] = ferdowsi_words.count(w) / len(ferdowsi_words)\n",
    "    unigram_p[1][w] = hafez_words.count(w) / len(hafez_words)\n",
    "    unigram_p[2][w] = molana_words.count(w) / len(molana_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigrams(lines):\n",
    "    return [b for l in lines for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:])]\n",
    "    \n",
    "# 0: ferdowsi, 1: hafez, 2: molana\n",
    "bigrams = []\n",
    "bigrams.append(create_bigrams(ferdowsi_lines_with_token))\n",
    "bigrams.append(create_bigrams(hafez_lines_with_token))\n",
    "bigrams.append(create_bigrams(molana_lines_with_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_probability(lines_with_token, bigram, dictionary):\n",
    "    bigram_p = {}\n",
    "    lines_joined = \" \".join(lines_with_token)\n",
    "    for couple in bigram:\n",
    "        if (couple[0] in dictionary) and (couple[1] in dictionary) and (couple not in bigram_p):\n",
    "            denominator = lines_joined.count(couple[0])\n",
    "            if denominator != 0:\n",
    "                bigram_p[couple] = lines_joined.count(\" \".join(couple)) / denominator\n",
    "    \n",
    "    return bigram_p\n",
    "\n",
    "bigram_p = []\n",
    "bigram_p.append(calculate_bigram_probability(ferdowsi_lines_with_token, bigrams[0], dictionary))\n",
    "bigram_p.append(calculate_bigram_probability(hafez_lines_with_token, bigrams[1], dictionary))\n",
    "bigram_p.append(calculate_bigram_probability(molana_lines_with_token, bigrams[2], dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
