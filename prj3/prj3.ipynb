{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training with train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_poem(file_name):\n",
    "    with open(file_name, 'r', encoding=\"utf-8\") as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "ferdowsi_lines = read_poem('train_set/ferdowsi_train.txt')\n",
    "hafez_lines = read_poem('train_set/hafez_train.txt')\n",
    "molana_lines = read_poem('train_set/molavi_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferdowsi length: 9000\n",
      "Hafez length: 7700\n",
      "Molana length: 8000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ferdowsi length: {len(ferdowsi_lines)}\")\n",
    "print(f\"Hafez length: {len(hafez_lines)}\")\n",
    "print(f\"Molana length: {len(molana_lines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = ferdowsi_lines + hafez_lines + molana_lines\n",
    "p_ferdowsdi = len(ferdowsi_lines) / len(all_lines)\n",
    "p_hafez = len(hafez_lines) / len(all_lines)\n",
    "p_molana = len(molana_lines) / len(all_lines)\n",
    "lang_probabilities = [p_ferdowsdi, p_hafez, p_molana]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferdowsi probability: 0.3643724696356275\n",
      "Hafez probability: 0.3117408906882591\n",
      "Molana probability: 0.32388663967611336\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ferdowsi probability: {p_ferdowsdi}\")\n",
    "print(f\"Hafez probability: {p_hafez}\")\n",
    "print(f\"Molana probability: {p_molana}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines_with_token = [f\"<S> {l} </S>\" for l in all_lines]\n",
    "ferdowsi_lines_with_token = [f\"<S> {l} </S>\" for l in ferdowsi_lines]\n",
    "hafez_lines_with_token = [f\"<S> {l} </S>\" for l in hafez_lines]\n",
    "molana_lines_with_token = [f\"<S> {l} </S>\" for l in molana_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S> جهان چون بزاری برآید همی </S>', '<S> بدو نیک روزی سرآید همی </S>', '<S> چو بستی کمر بر در راه آز </S>']\n",
      "['<S> جهان چون بزاری برآید همی </S>', '<S> بدو نیک روزی سرآید همی </S>', '<S> چو بستی کمر بر در راه آز </S>']\n",
      "['<S> الا یا ایها الساقی ادر کاسا و ناولها </S>', '<S> که عشق آسان نمود اول ولی افتاد مشکل\\u200cها </S>', '<S> به بوی نافه\\u200cای کاخر صبا زان طره بگشاید </S>']\n",
      "['<S> بشنو از نی ، چون حکایت می\\u200cکند </S>', '<S> واز جدائی\\u200cها شکایت می\\u200cکند </S>', '<S> کز نیستان تا مرا ببریده اند </S>']\n"
     ]
    }
   ],
   "source": [
    "print(all_lines_with_token[:3])\n",
    "print(ferdowsi_lines_with_token[:3])\n",
    "print(hafez_lines_with_token[:3])\n",
    "print(molana_lines_with_token[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = \" \".join(all_lines_with_token).split(\" \")\n",
    "ferdowsi_words = \" \".join(ferdowsi_lines_with_token).split(\" \")\n",
    "hafez_words = \" \".join(hafez_lines_with_token).split(\" \")\n",
    "molana_words = \" \".join(molana_lines_with_token).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S>', 'جهان', 'چون', 'بزاری', 'برآید', 'همی', '</S>', '<S>', 'بدو', 'نیک']\n",
      "['<S>', 'جهان', 'چون', 'بزاری', 'برآید', 'همی', '</S>', '<S>', 'بدو', 'نیک']\n",
      "['<S>', 'الا', 'یا', 'ایها', 'الساقی', 'ادر', 'کاسا', 'و', 'ناولها', '</S>']\n",
      "['<S>', 'بشنو', 'از', 'نی', '،', 'چون', 'حکایت', 'می\\u200cکند', '</S>', '<S>']\n"
     ]
    }
   ],
   "source": [
    "print(all_words[:10])\n",
    "print(ferdowsi_words[:10])\n",
    "print(hafez_words[:10])\n",
    "print(molana_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17158\n"
     ]
    }
   ],
   "source": [
    "all_words_set = set(all_words)\n",
    "print(len(all_words_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creating dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8075"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = [w for w in all_words_set if all_words.count(w) >= 2]\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Unigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: ferdowsi, 1: hafez, 2: molana\n",
    "unigram_p = [{}, {}, {}]\n",
    "for w in dictionary:\n",
    "    unigram_p[0][w] = ferdowsi_words.count(w) / len(ferdowsi_words)\n",
    "    unigram_p[1][w] = hafez_words.count(w) / len(hafez_words)\n",
    "    unigram_p[2][w] = molana_words.count(w) / len(molana_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigrams(lines):\n",
    "    return [b for l in lines for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:])]\n",
    "    \n",
    "# 0: ferdowsi, 1: hafez, 2: molana\n",
    "bigrams = []\n",
    "bigrams.append(create_bigrams(ferdowsi_lines_with_token))\n",
    "bigrams.append(create_bigrams(hafez_lines_with_token))\n",
    "bigrams.append(create_bigrams(molana_lines_with_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_probability(lines_with_token, bigram, dictionary):\n",
    "    bigram_p = {}\n",
    "    lines_joined = \" \".join(lines_with_token)\n",
    "    for couple in bigram:\n",
    "        if (couple[0] in dictionary) and (couple[1] in dictionary) and (couple not in bigram_p):\n",
    "            denominator = lines_joined.count(couple[0])\n",
    "            if denominator != 0:\n",
    "                bigram_p[couple] = lines_joined.count(\" \".join(couple)) / denominator\n",
    "    \n",
    "    return bigram_p\n",
    "\n",
    "bigram_p = []\n",
    "bigram_p.append(calculate_bigram_probability(ferdowsi_lines_with_token, bigrams[0], dictionary))\n",
    "bigram_p.append(calculate_bigram_probability(hafez_lines_with_token, bigrams[1], dictionary))\n",
    "bigram_p.append(calculate_bigram_probability(molana_lines_with_token, bigrams[2], dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Backoff model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff_model(line_with_token, unigram_p, bigram_p, lambdas, epsilon):\n",
    "    assert abs(lambdas[0] + lambdas[1] + lambdas[2] - 1) < 1e-5\n",
    "    \n",
    "    splitted_line = line_with_token.split(\" \")\n",
    "    unigram = splitted_line\n",
    "    bigram = [b for b in zip(splitted_line[:-1], splitted_line[1:])]\n",
    "    \n",
    "    probabilities = [p for p in lang_probabilities]\n",
    "    for couple in bigram:\n",
    "        for i in range(3):\n",
    "            probabilities[i] *= lambdas[0] * bigram_p[i].get(couple, 0) + lambdas[1] * unigram_p[i].get(couple[1], 0) + lambdas[2] * epsilon\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Testing with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "with open(\"test_set/test_file.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f.read().splitlines():\n",
    "        y, x = line.strip().split(\"\\t\")\n",
    "        X_test.append(f\"<S> {x} </S>\")\n",
    "        Y_test.append(int(y) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S> وزان جایگه نالهٔ گاودم </S>', '<S> شنیدند و آواز رویینه خم </S>', '<S> جهاندار بیدار لشکر براند </S>']\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:3])\n",
    "print(Y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_max(input_list):\n",
    "    return max(zip(input_list, range(len(input_list))))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(line_with_token, unigram_p, bigram_p, lambdas, epsilon):\n",
    "    probabilities = backoff_model(line_with_token, unigram_p, bigram_p, lambdas, epsilon)\n",
    "    return arg_max(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_test[0], unigram_p, bigram_p, (0.8, 0.15, 0.05), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(X_test, Y_test, unigram_p, bigram_p, lambdas, epsilon):\n",
    "    correct = 0\n",
    "    for index, line in enumerate(X_test):\n",
    "        if predict(line, unigram_p, bigram_p, lambdas, epsilon) == Y_test[index]:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters #1:\n",
    "$\\lambda_3 = 0.5, \\lambda_2 = 0.48, \\lambda_1 = 0.02, \\epsilon = 0.01$\n",
    "\n",
    "$Accuracy: 0.8404$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8404796511627907"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy(X_test, Y_test, unigram_p, bigram_p, (0.5, 0.48, 0.02), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas: (0.8, 0.15, 0.05), Epsilon: 1e-05\t\t, Accuracy: 0.8710029069767442\n",
      "Lambdas: (0.8, 0.15, 0.05), Epsilon: 3e-06\t\t, Accuracy: 0.873546511627907\n",
      "Lambdas: (0.82, 0.13, 0.05), Epsilon: 1e-05\t\t, Accuracy: 0.8699127906976745\n",
      "Lambdas: (0.82, 0.13, 0.05), Epsilon: 3e-06\t\t, Accuracy: 0.873546511627907\n",
      "Lambdas: (0.84, 0.11, 0.05), Epsilon: 1e-05\t\t, Accuracy: 0.8695494186046512\n",
      "Lambdas: (0.84, 0.11, 0.05), Epsilon: 3e-06\t\t, Accuracy: 0.8728197674418605\n",
      "Lambdas: (0.86, 0.09, 0.05), Epsilon: 1e-05\t\t, Accuracy: 0.8680959302325582\n",
      "Lambdas: (0.86, 0.09, 0.05), Epsilon: 3e-06\t\t, Accuracy: 0.8717296511627907\n",
      "Lambdas: (0.88, 0.07, 0.05), Epsilon: 1e-05\t\t, Accuracy: 0.8666424418604651\n",
      "Lambdas: (0.88, 0.07, 0.05), Epsilon: 3e-06\t\t, Accuracy: 0.8706395348837209\n",
      "Lambdas: (0.9, 0.05, 0.05), Epsilon: 1e-05\t\t, Accuracy: 0.8626453488372093\n",
      "Lambdas: (0.9, 0.05, 0.05), Epsilon: 3e-06\t\t, Accuracy: 0.8702761627906976\n"
     ]
    }
   ],
   "source": [
    "# for lambdas in [(0.5, 0.48, 0.02), (0.6, 0.38, 0.02), (0.7, 0.28, 0.02), (0.8, 0.18, 0.02), (0.9, 0.08, 0.02)]:\n",
    "# for lambdas in [(0.8, 0.13, 0.07), (0.8, 0.14, 0.06), (0.8, 0.15, 0.05), (0.8, 0.16, 0.04), (0.8, 0.17, 0.03), (0.8, 0.18, 0.02), (0.8, 0.19, 0.01)]:\n",
    "for lambdas in [(0.8, 0.15, 0.05), (0.82, 0.13, 0.05), (0.84, 0.11, 0.05), (0.86, 0.09, 0.05), (0.88, 0.07, 0.05), (0.9, 0.05, 0.05)]:\n",
    "#     for epsilon in [1, 3e-1, 1e-2, 3e-2, 1e-2, 3e-3, 1e-3, 3e-4, 1e-4]:\n",
    "#     for epsilon in [3e-4, 1e-4, 3e-5, 1e-5, 3e-6, 1e-6]:\n",
    "    for epsilon in [1e-5, 3e-6]:\n",
    "        acc = model_accuracy(X_test, Y_test, unigram_p, bigram_p, lambdas, epsilon)\n",
    "        print(f\"Lambdas: {lambdas}, Epsilon: {epsilon}\\t\\t, Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters #2:\n",
    "$\\lambda_3 = 0.8, \\lambda_2 = 0.15, \\lambda_1 = 0.05, \\epsilon = 0.01$\n",
    "\n",
    "$Accuracy: 0.8077$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8077761627906976"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy(X_test, Y_test, unigram_p, bigram_p, (0.8, 0.15, 0.05), 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters #3:\n",
    "$\\lambda_3 = 0.5, \\lambda_2 = 0.48, \\lambda_1 = 0.02, \\epsilon = 3e-06$\n",
    "\n",
    "$Accuracy: 0.8611$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8611918604651163"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy(X_test, Y_test, unigram_p, bigram_p, (0.5, 0.48, 0.02), 3e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters #4:\n",
    "$\\lambda_3 = 0.8, \\lambda_2 = 0.15, \\lambda_1 = 0.05, \\epsilon = 3e-06$\n",
    "\n",
    "$Accuracy: 0.8735$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873546511627907"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy(X_test, Y_test, unigram_p, bigram_p, (0.8, 0.15, 0.05), 3e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "به نظر می‌رسد بهترین پارامترها را [حالت چهارم](#Hyperparameters-%234%3A) هستند که در این حالت دقت مدل در حدود ۸۷.۳۵ درصد است که دقت مناسبی است.\n",
    "\n",
    "\n",
    "علت مناسب بودن این پارامترها این است که در این حالت برای کلمه‌هایی که در واژه‌نامه وجود ندارند، تنها یک احتمال بسیار کوچک (برای صفر نشدن احتمال کل جمله) در نظر گرفته می‌شود. هم‌چنین در این حالت وزن بالایی به مدل بایگرام داده می‌شود. از آنجا که تقریب بایگرام تقریب دقیق‌تری است، وزن بیشتر این تقریب نسبت به تقریب یونی‌گرام، باعث بهتر شدن دقت مدل شده است."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
