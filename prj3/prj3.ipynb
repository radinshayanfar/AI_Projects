{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_poem(file_name):\n",
    "    with open(file_name, 'r', encoding=\"utf-8\") as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "ferdowsi_lines = read_poem('train_set/ferdowsi_train.txt')\n",
    "hafez_lines = read_poem('train_set/hafez_train.txt')\n",
    "molana_lines = read_poem('train_set/molavi_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferdowsi length: 9000\n",
      "Hafez length: 7700\n",
      "Molana length: 8000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ferdowsi length: {len(ferdowsi_lines)}\")\n",
    "print(f\"Hafez length: {len(hafez_lines)}\")\n",
    "print(f\"Molana length: {len(molana_lines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = ferdowsi_lines + hafez_lines + molana_lines\n",
    "p_ferdowsdi = len(ferdowsi_lines) / len(all_lines)\n",
    "p_hafez = len(hafez_lines) / len(all_lines)\n",
    "p_molana = len(molana_lines) / len(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferdowsi probability: 0.3643724696356275\n",
      "Hafez probability: 0.3117408906882591\n",
      "Molana probability: 0.32388663967611336\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ferdowsi probability: {p_ferdowsdi}\")\n",
    "print(f\"Hafez probability: {p_hafez}\")\n",
    "print(f\"Molana probability: {p_molana}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines_with_token = [f\"<S> {l} </S>\" for l in all_lines]\n",
    "ferdowsi_lines_with_token = [f\"<S> {l} </S>\" for l in ferdowsi_lines]\n",
    "hafez_lines_with_token = [f\"<S> {l} </S>\" for l in hafez_lines]\n",
    "molana_lines_with_token = [f\"<S> {l} </S>\" for l in molana_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S> جهان چون بزاری برآید همی </S>', '<S> بدو نیک روزی سرآید همی </S>', '<S> چو بستی کمر بر در راه آز </S>']\n",
      "['<S> جهان چون بزاری برآید همی </S>', '<S> بدو نیک روزی سرآید همی </S>', '<S> چو بستی کمر بر در راه آز </S>']\n",
      "['<S> الا یا ایها الساقی ادر کاسا و ناولها </S>', '<S> که عشق آسان نمود اول ولی افتاد مشکل\\u200cها </S>', '<S> به بوی نافه\\u200cای کاخر صبا زان طره بگشاید </S>']\n",
      "['<S> بشنو از نی ، چون حکایت می\\u200cکند </S>', '<S> واز جدائی\\u200cها شکایت می\\u200cکند </S>', '<S> کز نیستان تا مرا ببریده اند </S>']\n"
     ]
    }
   ],
   "source": [
    "print(all_lines_with_token[:3])\n",
    "print(ferdowsi_lines_with_token[:3])\n",
    "print(hafez_lines_with_token[:3])\n",
    "print(molana_lines_with_token[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = \" \".join(all_lines_with_token).split(\" \")\n",
    "ferdowsi_words = \" \".join(ferdowsi_lines_with_token).split(\" \")\n",
    "hafez_words = \" \".join(hafez_lines_with_token).split(\" \")\n",
    "molana_words = \" \".join(molana_lines_with_token).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S>', 'جهان', 'چون', 'بزاری', 'برآید', 'همی', '</S>', '<S>', 'بدو', 'نیک']\n",
      "['<S>', 'جهان', 'چون', 'بزاری', 'برآید', 'همی', '</S>', '<S>', 'بدو', 'نیک']\n",
      "['<S>', 'الا', 'یا', 'ایها', 'الساقی', 'ادر', 'کاسا', 'و', 'ناولها', '</S>']\n",
      "['<S>', 'بشنو', 'از', 'نی', '،', 'چون', 'حکایت', 'می\\u200cکند', '</S>', '<S>']\n"
     ]
    }
   ],
   "source": [
    "print(all_words[:10])\n",
    "print(ferdowsi_words[:10])\n",
    "print(hafez_words[:10])\n",
    "print(molana_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17158\n"
     ]
    }
   ],
   "source": [
    "all_words_set = set(all_words)\n",
    "print(len(all_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8075"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = [w for w in all_words_set if all_words.count(w) >= 2]\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: ferdowsi, 1: hafez, 2: molana\n",
    "unigram_p = [{}, {}, {}]\n",
    "for w in dictionary:\n",
    "    unigram_p[0][w] = ferdowsi_words.count(w) / len(ferdowsi_words)\n",
    "    unigram_p[1][w] = hafez_words.count(w) / len(hafez_words)\n",
    "    unigram_p[2][w] = molana_words.count(w) / len(molana_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigrams(lines):\n",
    "    return [b for l in lines for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:])]\n",
    "    \n",
    "# 0: ferdowsi, 1: hafez, 2: molana\n",
    "bigrams = []\n",
    "bigrams.append(create_bigrams(ferdowsi_lines_with_token))\n",
    "bigrams.append(create_bigrams(hafez_lines_with_token))\n",
    "bigrams.append(create_bigrams(molana_lines_with_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_probability(lines_with_token, bigram, dictionary):\n",
    "    bigram_p = {}\n",
    "    lines_joined = \" \".join(lines_with_token)\n",
    "    for couple in bigram:\n",
    "        if (couple[0] in dictionary) and (couple[1] in dictionary) and (couple not in bigram_p):\n",
    "            denominator = lines_joined.count(couple[0])\n",
    "            if denominator != 0:\n",
    "                bigram_p[couple] = lines_joined.count(\" \".join(couple)) / denominator\n",
    "    \n",
    "    return bigram_p\n",
    "\n",
    "bigram_p = []\n",
    "bigram_p.append(calculate_bigram_probability(ferdowsi_lines_with_token, bigrams[0], dictionary))\n",
    "bigram_p.append(calculate_bigram_probability(hafez_lines_with_token, bigrams[1], dictionary))\n",
    "bigram_p.append(calculate_bigram_probability(molana_lines_with_token, bigrams[2], dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "with open(\"test_set/test_file.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f.read().splitlines():\n",
    "        y, x = line.strip().split(\"\\t\")\n",
    "        X_test.append(f\"<S> {x} </S>\")\n",
    "        Y_test.append(int(y) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S> وزان جایگه نالهٔ گاودم </S>', '<S> شنیدند و آواز رویینه خم </S>', '<S> جهاندار بیدار لشکر براند </S>']\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:3])\n",
    "print(Y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff_model(line_with_token, unigram_p, bigram_p, lambdas, epsilon):\n",
    "    assert abs(lambdas[0] + lambdas[1] + lambdas[2] - 1) < 1e-5\n",
    "    \n",
    "    splitted_line = line_with_token.split(\" \")\n",
    "    unigram = splitted_line\n",
    "    bigram = [b for b in zip(splitted_line[:-1], splitted_line[1:])]\n",
    "    \n",
    "    probabilities = [1 for i in range(3)]\n",
    "    for couple in bigram:\n",
    "        for i in range(3):\n",
    "            probabilities[i] *= lambdas[0] * bigram_p[i].get(couple, 0) + lambdas[1] * unigram_p[i].get(couple[1], 0) + lambdas[2] * epsilon\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_max(input_list):\n",
    "    return max(zip(input_list, range(len(input_list))))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(line_with_token, unigram_p, bigram_p, lambdas, epsilon):\n",
    "    probabilities = backoff_model(line_with_token, unigram_p, bigram_p, lambdas, epsilon)\n",
    "    return arg_max(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_test[0], unigram_p, bigram_p, (0.8, 0.15, 0.05), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(X_test, Y_test, unigram_p, bigram_p, lambdas, epsilon):\n",
    "    correct = 0\n",
    "    for index, line in enumerate(X_test):\n",
    "        if predict(line, unigram_p, bigram_p, lambdas, epsilon) == Y_test[index]:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters #1:\n",
    "$\\lambda_3 = 0.8, \\lambda_2 = 0.15, \\lambda_1 = 0.02, \\epsilon = 1e-03$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8393895348837209"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy(X_test, Y_test, unigram_p, bigram_p, (0.8, 0.15, 0.05), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 1\t\t, Accuracy: 0.7285610465116279\n",
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 0.3\t\t, Accuracy: 0.7605377906976745\n",
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.840843023255814\n",
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 0.03\t\t, Accuracy: 0.8201308139534884\n",
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.840843023255814\n",
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 0.003\t\t, Accuracy: 0.8499273255813954\n",
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 0.001\t\t, Accuracy: 0.862281976744186\n",
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 0.0003\t\t, Accuracy: 0.8659156976744186\n",
      "Lambdas: (0.5, 0.48, 0.02), Epsilon: 0.0001\t\t, Accuracy: 0.8677325581395349\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 1\t\t, Accuracy: 0.7300145348837209\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 0.3\t\t, Accuracy: 0.7579941860465116\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.8375726744186046\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 0.03\t\t, Accuracy: 0.8132267441860465\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.8375726744186046\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 0.003\t\t, Accuracy: 0.8473837209302325\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 0.001\t\t, Accuracy: 0.8568313953488372\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 0.0003\t\t, Accuracy: 0.8644622093023255\n",
      "Lambdas: (0.6, 0.38, 0.02), Epsilon: 0.0001\t\t, Accuracy: 0.8680959302325582\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 1\t\t, Accuracy: 0.7311046511627907\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 0.3\t\t, Accuracy: 0.7579941860465116\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.831031976744186\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 0.03\t\t, Accuracy: 0.8135901162790697\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.831031976744186\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 0.003\t\t, Accuracy: 0.8459302325581395\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 0.001\t\t, Accuracy: 0.8524709302325582\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 0.0003\t\t, Accuracy: 0.8630087209302325\n",
      "Lambdas: (0.7, 0.28, 0.02), Epsilon: 0.0001\t\t, Accuracy: 0.8666424418604651\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 1\t\t, Accuracy: 0.732921511627907\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 0.3\t\t, Accuracy: 0.7583575581395349\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.825218023255814\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 0.03\t\t, Accuracy: 0.8066860465116279\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.825218023255814\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 0.003\t\t, Accuracy: 0.8397529069767442\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 0.001\t\t, Accuracy: 0.8477470930232558\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 0.0003\t\t, Accuracy: 0.8597383720930233\n",
      "Lambdas: (0.8, 0.18, 0.02), Epsilon: 0.0001\t\t, Accuracy: 0.8648255813953488\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 1\t\t, Accuracy: 0.734375\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 0.3\t\t, Accuracy: 0.7565406976744186\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.8179505813953488\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 0.03\t\t, Accuracy: 0.799781976744186\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 0.01\t\t, Accuracy: 0.8179505813953488\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 0.003\t\t, Accuracy: 0.8317587209302325\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 0.001\t\t, Accuracy: 0.8393895348837209\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 0.0003\t\t, Accuracy: 0.8492005813953488\n",
      "Lambdas: (0.9, 0.08, 0.02), Epsilon: 0.0001\t\t, Accuracy: 0.8568313953488372\n"
     ]
    }
   ],
   "source": [
    "for lambdas in [(0.5, 0.48, 0.02), (0.6, 0.38, 0.02), (0.7, 0.28, 0.02), (0.8, 0.18, 0.02), (0.9, 0.08, 0.02)]:\n",
    "# for lambdas in [(0.8, 0.15, 0.05), (0.8, 0.16, 0.04), (0.8, 0.17, 0.03), (0.8, 0.18, 0.02), (0.8, 0.19, 0.01)]:\n",
    "# for lambdas in [(0.8, 0.18, 0.02), (0.82, 0.16, 0.02), (0.84, 0.14, 0.02), (0.86, 0.12, 0.02), (0.88, 0.10, 0.02), (0.9, 0.08, 0.02)]:\n",
    "    for epsilon in [1, 3e-1, 1e-2, 3e-2, 1e-2, 3e-3, 1e-3, 3e-4, 1e-4]:\n",
    "#     for epsilon in [3e-4, 1e-4, 3e-5, 1e-5, 3e-6, 1e-6]:\n",
    "#     for epsilon in [1e-5, 3e-6]:\n",
    "        acc = model_accuracy(X_test, Y_test, unigram_p, bigram_p, lambdas, epsilon)\n",
    "        print(f\"Lambdas: {lambdas}, Epsilon: {epsilon}\\t\\t, Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters #2:\n",
    "$\\lambda_3 = 0.8, \\lambda_2 = 0.18, \\lambda_1 = 0.02, \\epsilon = 1e-05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873546511627907"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy(X_test, Y_test, unigram_p, bigram_p, (0.8, 0.18, 0.02), 1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
